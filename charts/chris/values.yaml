# This file is for cutomizing how chris is deployed.

# Name
#####################

nameOverride: "chris1222"
fullnameOverride: "chris1222"


# Stuff you can typically ignore
#####################

imagePullSecrets: []

# Global settings
#####################

global:
  # storage class to use for persistent volume claims
  storageClass: "rc-nfs"

  # optional security context to apply to all pods
  podSecurityContext:
    runAsUser: 7748
    runAsGroup: 1102


# Not used
serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""


# Ingress and HTTPS
ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: Prefix
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# OpenShift route
route:
  enabled: false
  host: chart-example.local
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
    destinationCACertificate: ''


# ChRIS automatic admin account
#####################

chris_admin:
  username: chris
  email: noreply@babymri.org
  # If no password is set, then a random password is created for you.
  password: chris1234

# ChRIS Backend
#####################
cube:
  image:
    repository: ghcr.io/fnndsc/cube
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: "latest"

  # Use inter-pod affinity as a workaround for using a ReadWriteOnce PersistentVolumeClaim
  enablePodAffinityWorkaround: false

  # Prefix to use for job names submitted to Kubernetes. Ideally, this should be unique for each CUBE instance.
  # The default behavior is to use the release name as the job prefix.
  # jobPrefix: ""

  # Configuration
  #####################
  config:
    # Configuration of the gunicorn WSGI server.
    # ref: https://docs.gunicorn.org/en/stable/settings.html
    GUNICORN_CMD_ARGS: "--workers=4 --timeout=3600"
    # smaller values increases responsiveness at the cost of resource usage and possibly concurrency bugs
    CUBE_CELERY_POLL_INTERVAL: "5.0"
    # HTTP server security settings
    DJANGO_ALLOWED_HOSTS: "*"  # note: * is okay if OpenShift router or k8s igress is validating host header
    DJANGO_CORS_ALLOW_ALL_ORIGINS: "true"
    DJANGO_CORS_ALLOWED_ORIGINS: ""
    DJANGO_SECURE_PROXY_SSL_HEADER: ""
    DJANGO_USE_X_FORWARDED_HOST: "false"
    # enable LDAP login
    AUTH_LDAP: "true"
    AUTH_LDAP_SERVER_URI: "ldap://fnndsc.tch.harvard.edu:389"
    AUTH_LDAP_BIND_DN: "cn=admin,dc=fnndsc"
    AUTH_LDAP_USER_SEARCH_ROOT: "dc=fnndsc"

  ## Additional secret environment variables for CUBE
  secrets:
     AUTH_LDAP_BIND_PASSWORD: "xzaq!@#$"

  # Set of default plugins to register with the coupled pfcon (if .pfcon.enabled)
  # Plugins which CUBE is hard-coded to depend on should be listed here.
  # To add plugins for general use, see https://chrisproject.org/docs/tutorials/upload_plugin
  plugins:
    - https://cube.chrisproject.org/api/v1/plugins/1/   # pl-dircopy
    - https://cube.chrisproject.org/api/v1/plugins/2/   # pl-tsdircopy
    - https://cube.chrisproject.org/api/v1/plugins/3/   # pl-topologicalcopy

  # Storage
  #####################
  # Persistent volume for CUBE files
  storage:
    # In the default configuration, the volume is managed by pfcon's subchart, so leave this as "enabled: false"
    enabled: false
    size: 100Gi
    accessModes: [ "ReadWriteOnce" ]
    storageClass: "rc-nfs"

  # Resources
  #####################
  workerMains:
    ## Resources for the main worker.
    ## It requires a large memory allocation due to an inefficient implementation.
    ## Recommended value is x4 the size of the largest anticipated plugin instance output directory.
    resources:
      requests:
        memory: 3814Mi
        cpu: 1
      limits:
        memory: 3814Mi
        cpu: 1

  workerPeriodic:
    ## Resources for the periodic worker.
    ## Default values should be okay. Memory request may be further reduced to ~400Mi.
    resources:
      requests:
        memory: 1Gi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 250m

  server:
    replicas: 1
    service:
      type: NodePort
      port: 8000
      nodePort: 31222
      ## nodePortHost does nothing. It is simply used to print the URL of CUBE in the NOTES
      # nodePortHost:
    podAnnotations: {}
    ## resources for the HTTP server (WSGI).
    ## Default values should be okay. About 256Mi of memory is needed per idle worker.
    resources:
      requests:
        memory: 2Gi
        cpu: 1
      limits:
        memory: 2Gi
        cpu: 1

# Database
#####################

# [SUBCHART] PostgreSQL packaged by Bitnami
# https://github.com/bitnami/charts/tree/main/bitnami/postgresql#parameters
postgresql:

  # no reason to change these values
  auth:
    database: "chris"
    username: "chris"

  # one of: [standalone, replication]
  # Replication is supported, see upstream README.md for configuration.
  architecture: standalone

  primary:
    # Primary database instance resource requests
    resources:
      requests:
        memory: 1Gi
        cpu: 1
      limits:
        memory: 1Gi
        cpu: 1

    persistence:
      enabled: true
      size: 8Gi

    # Defer control of security configurations to OpenShift
    podSecurityContext:
      enabled: true
      fsGroup: 1102
    containerSecurityContext:
      enabled: true
      runAsUser: 7748
  volumePermissions:
    enabled: false
  shmVolume:
    enabled: false

# [SUBCHART] RabbitMQ packaged by Bitnami
# https://github.com/bitnami/charts/tree/main/bitnami/rabbitmq#parameters
rabbitmq:

  # No reason to change these values.
  #
  # Whether or not to set a password for RabbitMQ depends on your threat model.
  # The RabbitMQ service does not receive ingress traffic, the password appears
  # here in values.yaml due to limitations of how Helm charts share variables
  # with subcharts.
  auth:
    username: "chris"
    password: "chris1234"

  persistence:
    enabled: true
    size: 1Gi
    storageClass: rc-nfs
    accessModes: ["ReadWriteMany"]

  # Defer control of security configurations to OpenShift
  podSecurityContext:
    enabled: true
    fsGroup: 1102
  containerSecurityContext:
    enabled: true
    runAsUser: 7748
  volumePermissions:
    enabled: false

  clusterDomain: k8s.galena.fnndsc

# pfcon: ChRIS compute resource
#####################

pfcon:
  enabled: true

  name: "innetwork"
  description: "Kubernetes cluster compute resource"
  replicaCount: 1
  podAnnotations: {}

  service:
    type: ClusterIP
    port: 5005

  nodeSelector: {}

  # Storage space for CUBE files should be configured here.
  # It is recommended to allocate as much space as possible for CUBE files.
  storage:
    existingClaim: ""
    size: 100Gi
    accessModes: [ "ReadWriteOnce" ]
    storageClass: rc-nfs

  pfcon:
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 384Mi

    workers: 4
    workerTimeout: 3600

    # pfcon configuration
    # Recommended to keep as-is
    config:
      innetwork: true
      storageEnv: filesystem

  pman:
    # It is unnecessary to increase pman's resources to above the minimum because
    # pman doesn't do anything besides sending and receiving HTTP requests.
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 1Gi

    workers: 4
    workerTimeout: 30

    # pman configuration
    # https://github.com/fnndsc/pman#environment-variables
    # SECRET_KEY, CONTAINER_ENV, STORAGE_TYPE, VOLUME_NAME, and CONTAINER_USER are handled automatically
    config:
      JOB_LABELS: chrisproject.org/job=plugininstance,chrisproject.org/chris-instance=chris1222
      ENABLE_HOME_WORKAROUND: "yes"
      REMOVE_JOBS: "yes"
      IGNORE_LIMITS: "no"

    # Set securityContext of containers created by pman to have the same securityContext as .global.podSecurityContext
    # or the default fnndsc/cube container user, so that the container user can write to the shared volume's filesystem.
    # Should be disabled on OpenShift.
    setSecurityContext: true


# pfdcm: ChRIS PACS connector
#####################

pfdcm:
  enabled: true
  image:
    repository: ghcr.io/fnndsc/pfdcm
    pullPolicy: IfNotPresent
    tag: "3.1.22"
  podAnnotations: {}
  service:
    enabled: true
    type: ClusterIP
    port: 4005
    # nodePort:
  route:
    enabled: false
  maxWorkers: 1
  resources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 1
      memory: 1Gi

  # DICOM application entity title
  aet: "CHRISV3"

  # Additional pfdcm configuration. Usually, you'll want to leave this empty.
  # pfdcm will be preconfigured with the CUBE and Orthanc of this chart.
  # If this pfdcm interacts with multiple CUBEs or multiple PACS servers,
  # add them here.
  additionalConfig:
    cube: {}
      # local:
      #   url: https://cube.example.org/api/v1/
      #   username: pfdcm
      #   password: pfdcm1234
    storage: {}
      # local:
      #   storagetype: fs
      #   storepath: /files
    pacs:
      services: 
        PACSDCM:
          info:
            aet: CHRISV3
            aet_listener: CHRISV3
            aec: PACSDCM
            serverIP: 134.174.12.21
            serverPort: "104"

  # DICOM listener for pfdcm. Enabled when pfdcm is enabled.
  listener:
    image:
      repository: ghcr.io/fnndsc/oxidicom
      pullPolicy: IfNotPresent
      tag: "1.0.2"
    podAnnotations: {}
    # The PACS server must be configured to push to this service.
    # If using Orthanc, the Helm chart will help you validate your
    # configuration of Orthanc's modailities to include this service.
    service:
      enabled: true
      type: NodePort
      port: 11111
      nodePort: 31032
    replicas: 1
    ## manual configuration of OpenTelemetry
    # env:
    #   - name: OTEL_RESOURCE_ATTRIBUTES
    #     value: service.name=oxidicom
    #   - name: OTEL_EXPORTER_OTLP_ENDPOINT
    #     value: http://tempo:4318
    config:
      ## number of times 
      # httpRetries: 3
      
      ## number of DICOM listener threads
      listenerThreads: 4

      ## number of threads to use for pushing files to CUBE
      pusherThreads: 2

      ## verbose logging
      # verbose: true

      ## strictPduLength, uncompressedOnly, and maxPduLength are strange DICOM
      ## options which you probably want to leave as their default values.
      # strictPduLength: true
      # uncompressedOnly: true
      # maxPduLength: 16384

      ## Addresses of the PACS pushing to us. Used for looking up the NumberOfSeriesRelatedInstances.
      ## Do not specify a value for pacsAddress if you are using the Orthanc sub-chart.
      # pacsAddress: pacs.server.local:4242
      pacsAddress: PACSDCM=134.174.12.21:104
    resources:
      # It's written in Rust!
      # with 16 threads, CPU usage peaks at 120m and memory usage peaks at 1.3 GiB
      limits:
        cpu: 500m
        memory: 1907Mi
      requests:
        cpu: 500m
        memory: 1907Mi

# PACS server
orthanc:
  # If Orthanc is enabled, it is recommended to also enable pfdcm.
  enabled: false
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  # Orthanc HTTP API and web app
  service:
    enabled: true
    type: ClusterIP
    port: 8042
    # nodePort:
  # PACS server
  dicomService:
    enabled: true
    type: ClusterIP
    port: 4242
    # nodePort:
  resources:
    limits:
      cpu: 1
      memory: 4Gi
    requests:
      cpu: 1
      memory: 4Gi
  config:
    # The logical name of this instance of Orthanc. This one is
    # displayed in Orthanc Explorer and at the URI "/system".
    name: "Orthanc"
    # Enable the transparent compression of the DICOM instances
    storageCompression: false
    # Action to take when the maximum storage is reached.
    # By default, the patients are recycled ("Recycle" mode).
    # In "Reject" mode, the sender will receive a 0xA700 DIMSE status code
    # if the instance was sent through C-Store, a 507 HTTP status code
    # if using the REST API and a 0xA700 Failure reason when using
    # DicomWeb Stow-RS 
    # Allowed values: "Recycle", "Reject"
    # (new in Orthanc 1.11.2)
    maximumStorageMode: Reject
    # Maximum size of the storage cache in MB.  The storage cache
    # is stored in RAM and contains a copy of recently accessed
    # files (written or read).  A value of "0" indicates the cache
    # is disabled.  (new in Orthanc 1.10.0)
    maximumStorageCacheSize: 0

    # The DICOM Application Entity Title
    dicomAet: "ORTHANC"
    # Check whether the called AET corresponds during a DICOM request
    dicomCheckCalledAet: false

    # The default encoding that is assumed for DICOM files without
    # "SpecificCharacterSet" DICOM tag, and that is used when answering
    # C-Find requests (including worklists). The allowed values are
    # "Ascii", "Utf8", "Latin1", "Latin2", "Latin3", "Latin4",
    # "Latin5", "Cyrillic", "Windows1251", "Arabic", "Greek", "Hebrew",
    # "Thai", "Japanese", and "Chinese".
    defaultEncoding: "Latin1"

    # Set the timeout (in seconds) after which the DICOM associations
    # are closed by the Orthanc SCP (server) if no further DIMSE
    # command is received from the SCU (client).
    dicomScpTimeout: 30

    # The timeout (in seconds) after which the DICOM associations are
    # considered as closed by the Orthanc SCU (client) if the remote
    # DICOM SCP (server) does not answer.
    dicomScuTimeout: 10

    # Whether or not the password protection is enabled
    AuthenticationEnabled: true

    # The list of the registered users. Because Orthanc uses HTTP
    # Basic Authentication, the passwords are stored as plain text.
    registeredUsers: {}

    # The list of the known DICOM modalities
    #
    # A fourth parameter is available to enable patches for a
    # specific PACS manufacturer. The allowed values are currently
    # "Generic" (default value), "StoreScp" (storescp tool from
    # DCMTK), "ClearCanvas", "MedInria", "Dcm4Chee", "SyngoVia",
    # "AgfaImpax" (Agfa IMPAX), "EFilm2" (eFilm version 2), and
    # "Vitrea". This parameter is case-sensitive.
    dicomModalities:
      # !!!IMPORTANT!!!
      # To use in combination with pfdcm, you MUST define a modality for
      # `.Values.pfdcm.aet`
      "ChRIS": [ "ChRIS", "NAME-oxidicom", 11111 ]
      # "clearcanvas" : [ "CLEARCANVAS", "192.168.1.1", 104, "ClearCanvas" ]

    # Whether Orthanc monitors its metrics (new in Orthanc 1.5.4). If
    # set to "true", the metrics can be retrieved at
    # "/tools/metrics-prometheus" formetted using the Prometheus
    # text-based exposition format.
    metricsEnabled: true

  ohif:
    enabled: true
    # BTW, it's impossible to configure Orthanc's OHIF to connect with pfdcm-dicomweb.

    # OHIF custom config file
    # https://orthanc.uclouvain.be/book/plugins/ohif.html#user-configuration-of-ohif
    # userConfiguration: |
    #   window.config = {
    #     extensions: [],
    #     modes: []
    #   }

  persistence:
    storage:
      size: 1Gi
      # storageClass: my-storage-class
      accessModes: [ ReadWriteOnce ]
    index:
      size: 1Gi
      # storageClass: my-storage-class
      accessModes: [ ReadWriteOnce ]
